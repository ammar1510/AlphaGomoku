defaults:
  - ppo: default
  - env: gomoku
  - _self_

# Overall training config from TrainConfig dataclass

# Rollout specific
num_envs: 128 # Batch size for parallel environments
rollout_length: 128 # Max steps per rollout buffer

# Training loop specific
total_timesteps: 1_000_000
eval_interval: 10 # Evaluate every N updates (NOTE: Evaluation logic not implemented yet)
checkpoint_interval: 50 # Save checkpoint every N updates
seed: 42

# WandB specific
wandb:
  project: "alphagomoku-ppo"
  entity: null # Set your wandb entity here or via env var WANDB_ENTITY
  run_name: null # If None, wandb generates one
  mode: "online" # or "disabled"

# Checkpointing specific
# Hydra automatically manages output directories.
# Checkpoints will be saved in the hydra output dir under 'checkpoints'
# The hydra:
#   run:
#     dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
# setting controls the base output directory.

# --- Hydra Specific Settings ---
hydra:
  run:
    # Output directory: workspace_root/artifacts/YYYY-MM-DD/HH-MM-SS
    dir: ${oc.env:PWD}/artifacts/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    # Configures the job name used in logs and potentially directory structure
    name: ${env.name}_ppo
  sweep:
    # Default output directory for multirun sweeps
    dir: ${oc.env:PWD}/artifacts/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num} 