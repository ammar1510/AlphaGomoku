{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e3898f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.rollout import run_selfplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6fb8786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "# Mock ActorCritic Model\n",
    "class MockActorCritic:\n",
    "    def apply(self, params, obs):\n",
    "        # Return dummy logits and value\n",
    "        batch_size = obs.shape[0]\n",
    "        board_size = obs.shape[1]\n",
    "        num_actions = board_size * board_size\n",
    "        # Simple logits (e.g., uniform or favoring one action)\n",
    "        dummy_logits = jnp.zeros((batch_size, board_size, board_size))\n",
    "        # Make one action slightly more likely to ensure selection is possible\n",
    "        dummy_logits = dummy_logits.at[:, 0, 0].set(1.0)\n",
    "        dummy_value = jnp.ones(batch_size) * 0.5 # Constant value\n",
    "        return dummy_logits, dummy_value\n",
    "\n",
    "    def sample_action(self, logits, rng_key):\n",
    "        # Sample deterministically for testing (e.g., always pick the highest logit)\n",
    "        # Or use the key for controlled randomness if needed\n",
    "        batch_size = logits.shape[0]\n",
    "        board_size = logits.shape[1]\n",
    "        flat_logits = logits.reshape(batch_size, -1)\n",
    "        flat_action_idx = jnp.argmax(flat_logits, axis=-1)\n",
    "        # Convert flat index back to (row, col)\n",
    "        action_row = flat_action_idx // board_size\n",
    "        action_col = flat_action_idx % board_size\n",
    "        action = jnp.stack([action_row, action_col], axis=-1)\n",
    "        return action\n",
    "\n",
    "    def evaluate_actions(self, params, states, actions):\n",
    "         # Needed for PPO trainer, return dummy values consistent with shapes\n",
    "        T, B = states.shape[0], states.shape[1] # Assuming states shape (T, B, H, W, C) or similar\n",
    "        action_log_probs = jnp.zeros((T, B)) - 1.0 # Dummy log prob\n",
    "        entropy = jnp.ones((T, B)) * 1.5 # Dummy entropy\n",
    "        values = jnp.ones((T, B)) * 0.5 # Dummy value\n",
    "        return action_log_probs, entropy, values\n",
    "\n",
    "\n",
    "# Mock Environment Functions\n",
    "def mock_reset_env(env_state):\n",
    "    board_size = env_state['board_size']\n",
    "    num_boards = env_state['num_boards']\n",
    "    initial_obs = jnp.zeros((num_boards, board_size, board_size), dtype=jnp.float32)\n",
    "    # Reset dones, board state etc.\n",
    "    env_state['boards'] = jnp.zeros_like(env_state['boards'])\n",
    "    env_state['dones'] = jnp.zeros(num_boards, dtype=jnp.bool_)\n",
    "    env_state['current_player'] = jnp.ones(num_boards, dtype=jnp.int32) # Player 1 starts\n",
    "    env_state['steps'] = 0\n",
    "    return env_state, initial_obs\n",
    "\n",
    "def mock_step_env(env_state, action):\n",
    "    # Simple mock step: Game ends after `max_mock_steps`, fixed reward\n",
    "    num_boards = env_state['num_boards']\n",
    "    board_size = env_state['board_size']\n",
    "    max_mock_steps = 5 # Let the mock game end quickly\n",
    "\n",
    "    env_state['steps'] += 1\n",
    "    dones = (env_state['steps'] >= max_mock_steps) | env_state['dones'] # Check if game should end\n",
    "    rewards = jnp.where(dones & ~env_state['dones'], 1.0, 0.0) # Reward 1.0 only on the step it becomes done\n",
    "    env_state['dones'] = dones\n",
    "    # Flip player (doesn't really matter for this mock logic)\n",
    "    env_state['current_player'] = 3 - env_state['current_player']\n",
    "    # Dummy next observation\n",
    "    next_obs = jnp.ones((num_boards, board_size, board_size)) * env_state['steps']\n",
    "\n",
    "    return env_state, next_obs, rewards, dones\n",
    "\n",
    "def mock_get_action_mask(env_state):\n",
    "    # Allow all actions\n",
    "    num_boards = env_state['num_boards']\n",
    "    board_size = env_state['board_size']\n",
    "    return jnp.ones((num_boards, board_size, board_size), dtype=jnp.bool_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "346892f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def test_run_selfplay(mock_env_state, mock_actor_critic_instance, mock_params, rng):\n",
    "    # Use the patched environment functions implicitly\n",
    "    max_mock_steps = 5 # Must match mock_step_env\n",
    "    board_size = mock_env_state[\"board_size\"]\n",
    "    num_boards = mock_env_state[\"num_boards\"]\n",
    "\n",
    "    trajectory, final_rng = run_selfplay(\n",
    "        mock_env_state, mock_actor_critic_instance, mock_params, rng\n",
    "    )\n",
    "\n",
    "    assert isinstance(trajectory, dict)\n",
    "    assert \"obs\" in trajectory\n",
    "    assert \"actions\" in trajectory\n",
    "    assert \"rewards\" in trajectory\n",
    "    assert \"masks\" in trajectory\n",
    "    # assert \"values\" in trajectory # run_selfplay doesn't collect values currently\n",
    "    assert \"episode_length\" in trajectory\n",
    "\n",
    "    T = trajectory[\"episode_length\"]\n",
    "    # In mock, all envs finish at the same time\n",
    "    assert T == max_mock_steps\n",
    "\n",
    "    assert trajectory[\"obs\"].shape == (T, num_boards, board_size, board_size)\n",
    "    assert trajectory[\"actions\"].shape == (T, num_boards, 2)\n",
    "    assert trajectory[\"rewards\"].shape == (T, num_boards)\n",
    "    assert trajectory[\"masks\"].shape == (T, num_boards)\n",
    "    # assert trajectory[\"values\"].shape == (T, num_boards)\n",
    "\n",
    "    # Check mask is False on the last step for all boards\n",
    "    assert jnp.all(~trajectory[\"masks\"][-1, :])\n",
    "    # Check mask is True on steps before last for all boards\n",
    "    if T > 1:\n",
    "         assert jnp.all(trajectory[\"masks\"][-2, :])\n",
    "\n",
    "    assert not jnp.array_equal(rng, final_rng) # RNG should be consumed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7f264210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_actor_critic_instance():\n",
    "    return MockActorCritic()\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_params():\n",
    "    # Params can be empty for our mock model\n",
    "    return FrozenDict({})\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_env_state():\n",
    "    board_size = 5\n",
    "    num_boards = 2 # Test with batch size > 1\n",
    "    return {\n",
    "        \"board_size\": board_size,\n",
    "        \"num_boards\": num_boards,\n",
    "        \"boards\": jnp.zeros((num_boards, board_size, board_size), dtype=jnp.int32),\n",
    "        \"current_player\": jnp.ones(num_boards, dtype=jnp.int32),\n",
    "        \"dones\": jnp.zeros(num_boards, dtype=jnp.bool_),\n",
    "        \"steps\": 0, # Custom field for mock step tracking\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def rng():\n",
    "    return jax.random.PRNGKey(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d0b95a8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "Failed",
     "evalue": "Fixture \"mock_env_state\" called directly. Fixtures are not meant to be called directly,\nbut are created automatically when test functions request them as parameters.\nSee https://docs.pytest.org/en/stable/explanation/fixtures.html for more information about fixtures, and\nhttps://docs.pytest.org/en/stable/deprecations.html#calling-fixtures-directly about how to update your code.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailed\u001b[0m                                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_run_selfplay(\u001b[43mmock_env_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, mock_actor_critic_instance(), mock_params(), rng())\n",
      "File \u001b[0;32m~/Desktop/AlphaGo/AlphaGomoku/.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1169\u001b[0m, in \u001b[0;36mwrap_function_to_error_out_if_called_directly.<locals>.result\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(function)\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresult\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1169\u001b[0m     \u001b[43mfail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpytrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AlphaGo/AlphaGomoku/.venv/lib/python3.12/site-packages/_pytest/outcomes.py:178\u001b[0m, in \u001b[0;36mfail\u001b[0;34m(reason, pytrace)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Explicitly fail an executing test with the given message.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m:param reason:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    The exception that is raised.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Failed(msg\u001b[38;5;241m=\u001b[39mreason, pytrace\u001b[38;5;241m=\u001b[39mpytrace)\n",
      "\u001b[0;31mFailed\u001b[0m: Fixture \"mock_env_state\" called directly. Fixtures are not meant to be called directly,\nbut are created automatically when test functions request them as parameters.\nSee https://docs.pytest.org/en/stable/explanation/fixtures.html for more information about fixtures, and\nhttps://docs.pytest.org/en/stable/deprecations.html#calling-fixtures-directly about how to update your code."
     ]
    }
   ],
   "source": [
    "\n",
    "test_run_selfplay(mock_env_state(), mock_actor_critic_instance(), mock_params(), rng())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8267e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "x = jnp.zeros((4,5,3,15,15))\n",
    "current_player = jnp.ones((4,5,3))\n",
    "prefix_shape = x.shape[:-2] # e.g., (batch,) or (T, batch) or ()\n",
    "board_shape = x.shape[-2:] # (board_size, board_size)\n",
    "\n",
    "# Add channel dimension for board state\n",
    "# Shape: (..., board_size, board_size, 1)\n",
    "x_proc = jnp.expand_dims(x, axis=-1)\n",
    "\n",
    "# Create player channel\n",
    "# Ensure current_player has the correct prefix shape\n",
    "player_array = jnp.broadcast_to(current_player, prefix_shape)\n",
    "print(player_array.shape)\n",
    "# Reshape player_array to (..., 1, 1, 1) for broadcasting to spatial dims\n",
    "player_array_reshaped = player_array.reshape(prefix_shape + (1,) * (len(board_shape) + 1))\n",
    "# Create the channel plane: (..., board_size, board_size, 1)\n",
    "player_channel = jnp.ones_like(x_proc) * player_array_reshaped\n",
    "\n",
    "# Concatenate board state and player channel\n",
    "# Shape: (..., board_size, board_size, 2)\n",
    "x_combined = jnp.concatenate([x_proc, player_channel], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21afc606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 3, 15, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90890817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
