# @package _global_
# Default configuration for Pong PPO Training

# PPO Hyperparameters
learning_rate: 2.5e-4
clip_ratio: 0.1
value_coef: 0.5
entropy_coef: 0.01
max_grad_norm: 0.5
gamma: 0.99
gae_lambda: 0.95
update_epochs: 4
seed: 42
batch_size: 1 # Batch size for mini-batch updates (env B is handled separately)

# Training settings
total_timesteps: 10000000 # Target total environment steps
log_interval: 10 # Log metrics every N training updates (episodes in this case)
checkpoint_dir: "pong_ppo_checkpoints" # Directory for Orbax checkpoints
save_interval_updates: 100 # Save checkpoint every N training updates

# Orbax settings
orbax_max_to_keep: 5 # Number of checkpoints to keep

# Model settings
model_activation: "tanh" # Activation function for the MLP layers in the model 